{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "import utils.config as config\n",
    "from utils.helpers import perform_ica_cleaning\n",
    "from utils.helpers import save_epochs\n",
    "from utils.config import DATASETS\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "### Defining constants and preparing stuff ###\n",
    "\n",
    "DATASET = DATASETS[\"Braboszcz2017\"]\n",
    "\n",
    "bids_root = os.path.join(DATASET.path, \"study1/raw/eeg/\")\n",
    "path_epochs = os.path.join(config.EPOCHS_PATH, \"internal_task/braboszcz2017/\")\n",
    "\n",
    "# EEG settings\n",
    "subjects = DATASET.subjects\n",
    "sessions = DATASET.sessions\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "\n",
    "### Defining functions ###\n",
    "\n",
    "def load_task_data(bids_root, subject_id, tasks):\n",
    "    \"\"\"\n",
    "    Load specific task EEG data for a subject from a BIDS-like dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - bids_root: str, path to the root of the dataset.\n",
    "    - subject_id: str, subject identifier (e.g., '088').\n",
    "    - tasks: list of str, the task names to load (e.g., ['med2', 'think2']).\n",
    "    \n",
    "    Returns:\n",
    "    - raw_dict: dict, containing MNE Raw objects for each task.\n",
    "    \"\"\"\n",
    "    # Define the subject's EEG folder\n",
    "    subject_path = os.path.join(bids_root, f\"sub-{subject_id}\", \"eeg\")\n",
    "    \n",
    "    if not os.path.exists(subject_path):\n",
    "        raise FileNotFoundError(f\"Subject folder not found: {subject_path}\")\n",
    "    \n",
    "    raw_dict = {}  # Dictionary to hold Raw objects for each task\n",
    "    \n",
    "    for task in tasks:\n",
    "        # Locate the BDF file for the specific task\n",
    "        bdf_file = os.path.join(subject_path, f\"sub-{subject_id}_task-{task}_eeg.bdf\")\n",
    "        if not os.path.exists(bdf_file):\n",
    "            print(f\"WARNING: BDF file not found for task '{task}'. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Load the BDF file\n",
    "        raw = mne.io.read_raw_bdf(bdf_file, preload=True)\n",
    "        print(f\"Loaded BDF file for task '{task}': {bdf_file}\")\n",
    "        \n",
    "        # Optionally, load metadata from JSON/TSV files\n",
    "        # Metadata file paths\n",
    "        json_file = os.path.join(subject_path, f\"sub-{subject_id}_task-{task}_eeg.json\")\n",
    "        tsv_file = os.path.join(subject_path, f\"sub-{subject_id}_task-{task}_channels.tsv\")\n",
    "        \n",
    "        metadata = {}\n",
    "        if os.path.exists(json_file):\n",
    "            with open(json_file, 'r') as f:\n",
    "                metadata['json'] = f.read()\n",
    "            print(f\"Loaded metadata JSON for task '{task}'\")\n",
    "        \n",
    "        if os.path.exists(tsv_file):\n",
    "            metadata['tsv'] = tsv_file  # Store TSV file path for later use if needed\n",
    "            print(f\"Loaded metadata TSV for task '{task}'\")\n",
    "        \n",
    "        # Add the loaded data and metadata to the dictionary\n",
    "        raw_dict[task] = {\n",
    "            'raw': raw,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "    \n",
    "    if not raw_dict:\n",
    "        raise ValueError(f\"No data was loaded for subject {subject_id} with tasks {tasks}.\")\n",
    "    \n",
    "    return raw_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the epochs and do ICA\n",
    "for subject in subjects:\n",
    "    file_path = os.path.join(path_epochs, f'sub-{subject}_epo.fif')\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"No epochs found for subject {subject} at {file_path}\")\n",
    "\n",
    "    print(f\"Loading {file_path}\")\n",
    "    epochs = mne.read_epochs(file_path, preload=True)\n",
    "\n",
    "    # Skip if epochs are not loaded\n",
    "    if epochs is None:\n",
    "        continue\n",
    "\n",
    "    # Extract epochs for each session\n",
    "    epochs_med2 = epochs[\"med2\"]\n",
    "    epochs_think2 = epochs[\"think2\"]\n",
    "\n",
    "    # Perform ICA on med2 epochs\n",
    "    cleaned_epochs_med2, ica_med2 = perform_ica_cleaning(epochs_med2, subject)\n",
    "\n",
    "    # Perform ICA on think2 epochs\n",
    "    cleaned_epochs_think2, ica_think2 = perform_ica_cleaning(epochs_think2, subject)\n",
    "\n",
    "    # concatenate the epochs\n",
    "    epochs_concat = mne.concatenate_epochs([cleaned_epochs_med2, cleaned_epochs_think2])\n",
    "\n",
    "    # Save the epochs\n",
    "    save_epochs(epochs_concat, path_epochs, subject, suffix=\"ica_cleaned\")\n",
    "    \n",
    "    del epochs\n",
    "    gc.collect()\n",
    "    print(f\"Memory after cleanup: {process.memory_info().rss / 1e6:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
